import dashscope
from typing import Dict, Any
from langgraph.graph import StateGraph, START, END
from dotenv import load_dotenv
import os
import re
import json
load_dotenv()  # è‡ªåŠ¨è¯»å– .env æ–‡ä»¶
dashscope.api_key = os.getenv("DASHSCOPE_API_KEY")

def extract_json(text: str) -> str:
    """
    æå–æ¨¡å‹è¾“å‡ºä¸­å¯èƒ½è¢« markdown åŒ…è£¹çš„ JSON å—ã€‚
    å¦‚æœæ‰¾ä¸åˆ° ```json åŒ…è£¹ï¼Œåˆ™ fallback ä¸ºä»ç¬¬ä¸€ä¸ª { å¼€å§‹ã€‚
    """
    pattern = r"```json\s*(\{.*?\})\s*```"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        return match.group(1)
    # fallbackï¼šå°è¯•ä»ç¬¬ä¸€ä¸ª { ä½ç½®æˆªæ–­
    return text[text.find("{"):]

class AudioAnalysisAgent:
    def __init__(self, model: str = "qwen-audio-turbo"):
        self.model = model

    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        audio_path = state["audio_path"]
        prompt = (
            "ä½ æ˜¯é¢è¯•è¯­éŸ³åˆ†æä¸“å®¶ï¼Œéœ€è¦å®Œæˆä¸¤ä¸ªä»»åŠ¡å¹¶ä»¥ç»“æ„åŒ– JSON æ ¼å¼è¾“å‡ºï¼š\n"
            "1. transcript: å°†éŸ³é¢‘å®Œæ•´è½¬å†™ä¸ºæ–‡å­—ï¼Œä¿ç•™è‡ªç„¶è¯­è¨€é£æ ¼ã€‚\n"
            "2. audio_analysis: å¯¹éŸ³é¢‘ç”¨ä¸­æ–‡è¿›è¡Œåˆ†æï¼ŒåŒ…æ‹¬ä»¥ä¸‹ç­‰ç»´åº¦ï¼š\n"
            "   - æè¿°è¯­é€Ÿï¼Œè¯­è°ƒï¼Œè¯­æ°”ï¼Œæƒ…ç»ªçŠ¶æ€ï¼Œè¡¨è¾¾é£æ ¼ç­‰ç‰¹å¾"
        )

        messages = [
            {
                "role": "user",
                "content": [
                    {"audio": str(audio_path)},
                    {"text": prompt}
                ]
            }
        ]

        response = dashscope.MultiModalConversation.call(
            model=self.model,
            messages=messages,
            result_format="message"
        )
        print(response)

        try:
            content = response["output"]["choices"][0]["message"]["content"]
            all_text = "\n".join(item["text"] for item in content if "text" in item)
            print("ğŸ“‹ æ¨¡å‹è¾“å‡ºï¼š\n", all_text)

            json_text = extract_json(all_text)
            print("ğŸ“¦ è§£æ JSONï¼š\n", json_text)

            parsed = json.loads(json_text)

            return {
                **state,
                "transcript": parsed.get("transcript", "æ— å›åº”"),
                "audio_analysis": parsed.get("audio_analysis", "æ— å›åº”")
            }

        except Exception as e:
            return {
                **state,
                "transcript": "",
                "audio_analysis": "",
                "error": f"æ¨¡å‹å“åº”è§£æå¤±è´¥: {e}",
                "raw_output": response
            }

# å®šä¹‰çŠ¶æ€ç»“æ„
class AudioState(Dict[str, Any]):
    """çŠ¶æ€å­—å…¸æ ¼å¼ï¼ŒåŒ…å«è¾“å…¥å’Œä¸­é—´è¾“å‡ºã€‚"""
    audio_path: str
    transcript: str
    audio_analysis: Dict[str, str]

def build_audio_graph():
    builder = StateGraph(AudioState)

    # åŠ å…¥èŠ‚ç‚¹
    builder.add_node("AudioAnalysis", AudioAnalysisAgent())

    # å›¾çš„æµç¨‹
    builder.add_edge(START, "AudioAnalysis")
    builder.add_edge("AudioAnalysis", END)

    return builder.compile()