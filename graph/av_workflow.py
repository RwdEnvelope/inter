from __future__ import annotations

import sys
import time
import threading
from pathlib import Path

# â—† æŠŠé¡¹ç›®æ ¹ç›®å½•åŠ å…¥ sys.pathï¼Œä¿è¯ `tools.*` å¯ä»¥è¢«æ­£ç¡® import
sys.path.append(str(Path(__file__).resolve().parent.parent))

from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langchain.tools import Tool

# ----------------------------------------------------------------------
# â‘  å¤ç”¨ä½ å·²æœ‰çš„å¯åŠ¨ / åœæ­¢å‡½æ•°
#    å¦‚æœ tools.analysis è·¯å¾„ä¸åŒï¼Œè¯·ç›¸åº”ä¿®æ”¹ import
from tools.analysis import start_av_recording, stop_av_recording
# ----------------------------------------------------------------------

# â‘¡ å®šä¹‰å­å›¾çŠ¶æ€ï¼ˆå¯æŒ‰éœ€æ‰©å±•ï¼‰
class AVState(dict):
    """graph.invoke æ—¶ä¼ å…¥/äº§å‡ºçš„çŠ¶æ€ dict"""
    recording_started: bool = False
    max_duration: int = 300
    result: dict | None = None


# â‘¢ å·¥å…·èŠ‚ç‚¹
def start_record(state: AVState):
    """
    state: å½“å‰çš„å›¾çŠ¶æ€ï¼ˆLangGraph è‡ªåŠ¨ä¼ å…¥ï¼‰
    è¿”å›å€¼: éœ€è¦å†™å› state çš„å¢é‡
    """
    msg = start_av_recording()     # âš ï¸ ä¸æ¥å—å‚æ•°çš„åº•å±‚å‡½æ•°
    return {"recording_started": True, "start_msg": msg}

def stop_record(state: AVState):
    print("ğŸŸ¥ stop_record èŠ‚ç‚¹è¢«è§¦å‘")
    result = stop_av_recording()
    return {"result": result}


import keyboard   # pip install keyboard

def wait_for_stop(state: AVState):
    print("ğŸŸ¡ å½•åˆ¶ä¸­ï¼ŒæŒ‰ Enter åœæ­¢ ...")
    t0 = time.time()
    while True:
        if keyboard.is_pressed("enter"):
            state["external_stop_signal"] = True
            print("ğŸ”´ æŒ‰é”®åœæ­¢")
            break
        if time.time() - t0 > state.get("max_duration", 300):
            print("â° è¶…æ—¶è‡ªåŠ¨åœæ­¢")
            break
        time.sleep(0.1)
    return {}


# â‘¤ æ„å»ºå­å›¾
g = StateGraph(AVState)
g.add_node("start_record", start_record)
g.add_node("wait", wait_for_stop)
g.add_node("stop_record", stop_record)

g.add_edge(START, "start_record")
g.add_edge("start_record", "wait")
g.add_edge("wait", "stop_record")
g.add_edge("stop_record", END)

av_subgraph = g.compile()


# ----------------------------------------------------------------------
# â‘¥ Tool åŒ…è£…å™¨ï¼šåŒæ—¶æ”¯æŒ dict ä½ç½®å‚æ•° & å…³é”®å­—å‚æ•°
def _wrapper(*args, **kwargs):
    """
    å…è®¸ä»¥ä¸‹ä¸¤ç§è°ƒç”¨ï¼š
        av_interview_tool.invoke({"external_stop_signal": True})
        av_interview_tool.invoke(external_stop_signal=True)
    éƒ½ä¼šè¢«æ•´ç†ä¸ºä¸€ä¸ª state dict ä¼ ç»™å­å›¾
    """
    if len(args) == 1 and isinstance(args[0], dict):
        state = args[0]
    else:
        # å…³é”®å­—æˆ–æ— å‚
        state = kwargs
    # é»˜è®¤è¶…æ—¶ 300 sï¼Œå¯é€šè¿‡ä¼  max_duration è¦†ç›–
    return av_subgraph.invoke(state)


av_interview_tool = Tool(
    name="av_interview_tool",
    description=(
        "ä¸€æ¬¡æ€§å®Œæˆé¢è¯•çš„éŸ³è§†é¢‘é‡‡é›†ä¸åˆ†æï¼Œ"
        "è¿”å› {'audio_dir','video_dir','audio_summary','video_summary'}"
    ),
    func=_wrapper,
)
# ----------------------------------------------------------------------


# â‘¦ å¿«é€Ÿè‡ªæµ‹ï¼š10 ç§’åè‡ªåŠ¨åœæ­¢
if __name__ == "__main__":
    # çŠ¶æ€ dictï¼Œç¨å stop_later çº¿ç¨‹ä¼šæŠŠ external_stop_signal å†™è¿›å»
    shared_state: dict = {"max_duration": 30}

    def stop_later(sec: int = 10):
        time.sleep(sec)
        shared_state["external_stop_signal"] = True
        print(f"â›”ï¸ {sec} ç§’åˆ°ï¼Œè‡ªåŠ¨å‘é€ stop ä¿¡å·")

    threading.Thread(target=stop_later, daemon=True).start()

    res = av_interview_tool.invoke(shared_state)
    print("âœ… å®Œæˆï¼Œè¿”å›ç»“æœï¼š")
    print(res)
